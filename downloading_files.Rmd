# Downloading files

Aaron Aknin and Ashkan Bozorgzad

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(dbplyr)
library(RSQLite)
library(dplyr)
library(XML)
library(jsonlite)
library(rvest)
library(httr)
```

So this Section is about how do you use r to download files. It is important to use the right method when importing a dataset in order to optimize its use. 

## Get/set your working directory

* A basic component of working with data is knowing your working directory
* The two main commands are ```getwd()``` and ```setwd()```. 
* Be aware of relative versus absolute paths

## Checking for and creating directories

`file.exists ("directoryName")` will check to see if the directory exists and `dir.create ("directoryName")` will create a directory if it doesn't exist. Here is an example checking for a "data" directory and creating it if it doesn't exist.

```{r}
if (!file.exists("data")){
        dir.create("data")
        }
```


## Download a file from the web

* Download a file from the internet
* Even if you could do this by hand, helps with reproducibility
* Important parameters are _url_, _destfile_, _method_
* Useful for downloading tab-delimited, csv, and other files

```{r, warning=FALSE,message=FALSE, echo=FALSE}
fileUrl <- "https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2020-financial-year-provisional/Download-data/annual-enterprise-survey-2020-financial-year-provisional-size-bands-csv.csv"
download.file(fileUrl,destfile="./data/output.csv",method= "curl")
```

The method that we're going to use is `curl`. This is necessary because this website is an https, secure website, and so if you're doing this from a Mac, you need to specify the method is curl in order for it to work. If you list the files in this data directory, You see that we now have one file in that directory, and it's the cameras.csv file.

```{r}
list.files( "./data" )
```

An important component of downloading files from the internet is that those files might change. So you want to keep track of the date that you downloaded the data, and you can do that with the date function. So you just assign to dateDownloaded the command date and that will give you the date that those data were downloaded.

```{r}
dateDownloaded <- date()
dateDownloaded
```

## Reading Local Files

* Loading flat files - read.table().
* This is the main function for reading data into R. 
* Flexible and robust but requires more parameters. 
* Reads the data into RAM so big data can cause problems.

```{r}
df <- read.table( "resources/downloading_files/output.csv" , sep = ",",header= TRUE )
head(df)
```

You can also use read.csv in the case that you have a csv file, it automatically sets sep equal to the quote comma and it automatically sets header = TRUE. 

```{r}
df <- read.csv( "resources/downloading_files/output.csv")
head(df)
```

### Some more important parameters

* quote - you can tell R whether there are any quoted values quote="" means no quotes.
* na.strings - set the character that represents a missing value.
* nrows - how many rows to read of the file (e.g. nrows=10 reads 10 lines).
* skip- number of lines to skip before starting to read


## Reading XML

* Extensible markup language
* Frequently used to store structured data
* Particularly widely used in internet applications
* Extracting XML is the basis for most web scraping
* Components
   * Markup - labels that give the text structure
   * Content - the actual text of the document


```{r}
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(sub("s", "", fileURL), useInternal = TRUE)
rootNode <- xmlRoot(doc)

xmlName(rootNode)

rootNode[[1]][[1]]
```

## Reading JSON

* Javascript Object Notation
* Lightweight data storage
* Common format for data from application programming interfaces (APIs)
* Similar structure to XML but different syntax/format
* Data stored as
  * Numbers (double)
  * Strings (double quoted)
  * Boolean (_true_ or _false_)
  * Array (ordered, comma separated enclosed in square brackets _[]_)
  * Object (unorderd, comma separated collection of key:value pairs in curley brackets _{}_)

```{r readJSON}
# extracting data from the website
jsonData <- fromJSON("https://data.ny.gov/api/views/9a8c-vfzj/rows.json?accessType=DOWNLOAD")
# extract the data node
food_market <- jsonData[['data']]
# assembling the data into data frames

food_market[1,19]
```

The `httr` package allows to connect to websites and to connect to APIs. It allows, when a `GET` request is made (a request to access the result of a search), to retrieve the result in the form of a text to be reworked. In general, a call to an API via `httr` is made as follows:

```{r}
url <- "https://world.openfoodfacts.org/api/v0/product/3017620425400.json"

results <- 
  httr::content(
    httr::GET(url),             # url to query
    as="text",                  # type of the output
    httr::content_type_json(),  # type of the answer
    encoding= "UTF-8"           # encoding of the answer
  )

jsonData <-fromJSON(results)
```

## Webscraping

* It can be a great way to get data 
* Many websites have information you may want to programaticaly read
* In some cases this is against the terms of service for the website
* Attempting to read too many pages too quickly can get your IP address blocked

In order to retrieve data from a web page we can use the `rvest` package. 

In order to begin parsing a web page, we must first request this data from the computer server that contains it. In `rvest`, the function that does this is the `read_html()` function. For this tutorial we will use a weather website, the National Weather Service website.

```{r}
page <- read_html("https://forecast.weather.gov/MapClick.php?lat=37.7771&lon=-122.4196#.Xl0j6BNKhTY")
page
```

The goal being to recover the temperatures, we will search via the developer mode of Google Chrome the identifier of the Html tags where the information is located. Exemple : <p class="temp temp-high">High: 63 Â°F</p>

```{r}
results = page  %>% html_nodes(".temp") %>% html_text()
results
```

It is hard to read, One way to deal with that is to, as we've seen before is to use the XML package. So again, we could use this same URL. Use the XML package, and parse the HTML again, using the InternalNodes to get the complete structure out. 

## dplyr Pachage

This section is about the dplyr package in R, which is a package specifically designed to help you work with data frames. So in this lecture we will just cover the basics to introduce the package and we'll talk about the verbs arrange, filter, select, mutate and rename.

### Load the dplyr package

The dataset we are going to work is a data set on  air pollution and weather variables in the city of Chicago for the years 1987 to 2005, and it's kind of daily data.

```{r}
chicago <- readRDS("resources/downloading_files/chicago.rds")
dim(chicago)
str(chicago)
```

### Select

Show the dataframe with the first 5 columns
```{r}
head(select(chicago, 1:5))
```

```{r}
names(chicago)[1:3]
```
 if we want to look at the columns starting with city and ending with D DPTP, which is the dew point column. I, and I want to include all the columns in between.

```{r}
head(select(chicago, city:dptp))
```

you can use the minus sign to say, I want to look at all the columns except for these. The columns indicated by this range. And you can use the select function to just say minus on that city colon dew point sequence. And you'll get all of the columns, except those few columns. 
```{r}
head(select(chicago, -(city:dptp)))
```

the equivalent code to do this in kind of regular R, without using the deplyr package is a little bit tricky

```{r}
i <- match("city", names(chicago))
j <- match("dptp", names(chicago))
head(chicago[, -(i:j)])
```

### Verbs
#### filter

The filter function is the next function in deplyr that we'll talk about and it's basically used subset rows based on conditions. So, for example, you might want to take all the rows in the Chicago data set where pm 2.5 is greater than 30

```{r}
chic.f <- filter(chicago, pm25tmean2 > 30)
head(select(chic.f, 1:3, pm25tmean2), 10)
```

you don't have to just subset rows based on values in one column. You can take multiple columns and create a more complicated logical sequence. here we are looking at pm2.5 greater than 30. As well as temperature greater than 80. 

```{r}
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(select(chic.f, 1:3, pm25tmean2, tmpd), 10)
```

#### arrange

The next function of range has a simple purpose. It's basically used to reorder the rows of a data frame based on the values of a column. 


```{r}
chicago <- arrange(chicago, date)
head(select(chicago, date, pm25tmean2), 3)
```

use the tail function to look at the last couple rows
```{r}
tail(select(chicago, date, pm25tmean2), 3)
```

To  arrange the rows in descending order, the desc function can be used

```{r}
chicago <- arrange(chicago, desc(date))
head(select(chicago, date, pm25tmean2), 3)
```
use the tail function to look at the last couple rows
```{r}
tail(select(chicago, date, pm25tmean2), 3)
```

#### rename

The rename function is very simple. it can be used to rename a variable in R.

```{r}
head(chicago[, 1:5], 3)
```
```{r}
chicago <- rename(chicago, dewpoint = dptp, pm25 = pm25tmean2)
head(chicago[, 1:5], 3)
```

#### mutate

The mutate function is used to simply transform existing variables or to create new variables. So here in this example we want to create a new variable called pm25detrend. And this is the pm25 variable with the mean subtracted off.

```{r}
chicago <- mutate(chicago, pm25detrend=pm25-mean(pm25, na.rm=TRUE))
head(select(chicago, pm25, pm25detrend))
```


#### group_by

Finally the group by function allows you to split a data frame according to Certain categorical variables.  in this example, we are going to create a temperature category variable which will indicate whether a given day was hot or cold, depending on whether the temperature was over 80 degrees or not.
 
```{r}
chicago <- mutate(chicago, tempcat = factor(1 * (tmpd > 80), labels = c("cold", "hot")))
hotcold <- group_by(chicago, tempcat)
summarize(hotcold, pm25 = mean(pm25, na.rm = TRUE),
o3 = max(o3tmean2),
no2 = median(no2tmean2))
```

We can also categorize the data set on on other variables. For example we might want to do a summary for each year in the data set. We can create I can use the mutate function to create a year variable.

```{r}
chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
years <- group_by(chicago, year)
summarize(years, pm25 = mean(pm25, na.rm = TRUE),
o3 = max(o3tmean2, na.rm = TRUE),
no2 = median(no2tmean2, na.rm = TRUE))
```

#### %>%

The dplyr package implements a special operator. That allows you to chain different operations. It allows you to see what operations are happening in a readable way. it's indicated by a percent symbol and then the greater than symbol and then the percent symbol. We will call it the pipeline operator. The idea it that you take a data set and you feed through a pipeline of operations to create a new data set. We have the Chicago data set and we want to mutate to create a month variable because we want to create a summary of each of the pollutant variables by month. Then we want to take the output of mutate. Then group by it use according to this month variable. finally we want to take the output of group by and then run it through summarize.


```{r}
chicago %>% mutate(month = as.POSIXlt(date)$mon + 1) %>% group_by(month) %>%  summarize(pm25 = mean(pm25, na.rm = TRUE),
    o3 = max(o3tmean2, na.rm = TRUE),
    no2 = median(no2tmean2, na.rm = TRUE))
```

### Connecting to SQL DataBase 

This part will teach us how to connect a SQL database with R and submit queries to it. For this we need `dbplyr` and `RSQLite` packages. 

Retrieve the SQL file the way you want. In our case we will retrieve it from a url and stock it in the data folder.

```{r}
download.file(url = "https://ndownloader.figshare.com/files/2292171", destfile = "data/db_sql.sqlite", mode = "wb")
```

We then connect the R terminal with the SQL database. 

```{r}
db <- DBI::dbConnect(RSQLite::SQLite(), "resources/downloading_files/db_sql.sqlite")
```

#### Querying the database with the SQL syntax

The `sql` function allows us to submit queries to the database using the SQL language. 

```{r}
tbl(db, sql("SELECT year, species_id, plot_id FROM surveys"))
```

#### Querying the database with the dplyr syntax

The same result can be achieved by using the dplyr syntax.

```{r}
surveys <- tbl(db, "surveys")
surveys %>% select(year, species_id, plot_id)
```

### Other benefit of dplyr

* dplyr can work with other data frame âbackendsâ 
* data.table for large fast tables
* SQL interface for relational databases via the DBI package
