<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 27 Tutorial on Cluster Analysis | EDAV Fall 2021 Tues/Thurs Community Contributions</title>
<meta name="description" content="Jannik Wiedenhaupt  27.1 What is Clustering Analysis? Clustering Analysis is a data exploration method and one of the most popular classification techniques. Clustering works by segregating data...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 27 Tutorial on Cluster Analysis | EDAV Fall 2021 Tues/Thurs Community Contributions">
<meta property="og:type" content="book">
<meta property="og:description" content="Jannik Wiedenhaupt  27.1 What is Clustering Analysis? Clustering Analysis is a data exploration method and one of the most popular classification techniques. Clustering works by segregating data...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 27 Tutorial on Cluster Analysis | EDAV Fall 2021 Tues/Thurs Community Contributions">
<meta name="twitter:description" content="Jannik Wiedenhaupt  27.1 What is Clustering Analysis? Clustering Analysis is a data exploration method and one of the most popular classification techniques. Clustering works by segregating data...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/plotly-binding-4.10.0/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script><script src="libs/d3-4.5.0/d3.min.js"></script><script src="libs/forceNetwork-binding-0.4/forceNetwork.js"></script><script src="libs/sankey-1/sankey.js"></script><script src="libs/sankeyNetwork-binding-0.4/sankeyNetwork.js"></script><link href="libs/vis-9.1.0/vis-network.min.css" rel="stylesheet">
<script src="libs/vis-9.1.0/vis-network.min.js"></script><script src="libs/visNetwork-binding-2.1.0/visNetwork.js"></script><link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet">
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script><script src="libs/dygraphs-1.1.1/shapes.js"></script><script src="libs/moment-2.8.4/moment.js"></script><script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script><script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script><script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script><script src="libs/proj4js-2.3.15/proj4.js"></script><link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet">
<script src="libs/highcharts-8.1.2/highcharts.js"></script><script src="libs/highcharts-8.1.2/highcharts-3d.js"></script><script src="libs/highcharts-8.1.2/highcharts-more.js"></script><script src="libs/highcharts-8.1.2/modules/stock.js"></script><script src="libs/highcharts-8.1.2/modules/map.js"></script><script src="libs/highcharts-8.1.2/modules/annotations.js"></script><script src="libs/highcharts-8.1.2/modules/data.js"></script><script src="libs/highcharts-8.1.2/modules/drilldown.js"></script><script src="libs/highcharts-8.1.2/modules/item-series.js"></script><script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script><script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script><script src="libs/highcharts-8.1.2/modules/exporting.js"></script><script src="libs/highcharts-8.1.2/modules/export-data.js"></script><script src="libs/highcharts-8.1.2/modules/funnel.js"></script><script src="libs/highcharts-8.1.2/modules/heatmap.js"></script><script src="libs/highcharts-8.1.2/modules/treemap.js"></script><script src="libs/highcharts-8.1.2/modules/sankey.js"></script><script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script><script src="libs/highcharts-8.1.2/modules/organization.js"></script><script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script><script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script><script src="libs/highcharts-8.1.2/modules/sunburst.js"></script><script src="libs/highcharts-8.1.2/modules/vector.js"></script><script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script><script src="libs/highcharts-8.1.2/modules/xrange.js"></script><script src="libs/highcharts-8.1.2/modules/tilemap.js"></script><script src="libs/highcharts-8.1.2/modules/venn.js"></script><script src="libs/highcharts-8.1.2/modules/gantt.js"></script><script src="libs/highcharts-8.1.2/modules/timeline.js"></script><script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script><script src="libs/highcharts-8.1.2/modules/bullet.js"></script><script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script><script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script><script src="libs/highcharts-8.1.2/modules/lollipop.js"></script><script src="libs/highcharts-8.1.2/modules/series-label.js"></script><script src="libs/highcharts-8.1.2/plugins/motion.js"></script><script src="libs/highcharts-8.1.2/custom/reset.js"></script><script src="libs/highcharts-8.1.2/modules/boost.js"></script><script src="libs/highchart-binding-0.8.2/highchart.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">EDAV Fall 2021 Tues/Thurs Community Contributions</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Welcome!</a></li>
<li><a class="" href="community-contribution.html"><span class="header-section-number">2</span> Community Contribution</a></li>
<li><a class="" href="github-submission-instructions.html"><span class="header-section-number">3</span> GitHub submission instructions</a></li>
<li><a class="" href="sample-project.html"><span class="header-section-number">4</span> Sample project</a></li>
<li class="book-part">Cheatsheets</li>
<li><a class="" href="statistics-in-r-vs-python.html"><span class="header-section-number">5</span> Statistics in R vs Python</a></li>
<li><a class="" href="data-visualization-with-seaborn.html"><span class="header-section-number">6</span> Data Visualization with Seaborn</a></li>
<li><a class="" href="how-to-make-your-own-r-package.html"><span class="header-section-number">7</span> How to Make Your Own R package</a></li>
<li><a class="" href="rchess-package-cheatsheet.html"><span class="header-section-number">8</span> RChess package cheatsheet</a></li>
<li><a class="" href="hypothesis-testing-cheatsheet.html"><span class="header-section-number">9</span> Hypothesis testing cheatsheet</a></li>
<li><a class="" href="interactive-web-visualizations-for-r-cheatsheet.html"><span class="header-section-number">10</span> Interactive web visualizations for R cheatsheet"</a></li>
<li><a class="" href="ggforce.html"><span class="header-section-number">11</span> ggforce</a></li>
<li><a class="" href="gganimate-cheatsheet.html"><span class="header-section-number">12</span> GGanimate cheatsheet</a></li>
<li><a class="" href="statistical-tests-and-parameter-estimations-in-r-cheatsheet.html"><span class="header-section-number">13</span> Statistical Tests and Parameter Estimations in R Cheatsheet</a></li>
<li><a class="" href="ggalluvial-cheat-sheet.html"><span class="header-section-number">14</span> ggalluvial-cheat-sheet</a></li>
<li><a class="" href="introduction-to-plotly.html"><span class="header-section-number">15</span> Introduction to plotly</a></li>
<li><a class="" href="draw-graphs-using-python-and-r.html"><span class="header-section-number">16</span> draw graphs using python and R</a></li>
<li><a class="" href="data-visualization-packages-in-r.html"><span class="header-section-number">17</span> Data Visualization Packages in R</a></li>
<li><a class="" href="esquisse-cheat-sheet.html"><span class="header-section-number">18</span> Esquisse Cheat sheet</a></li>
<li><a class="" href="review-sheet-for-r-code-and-data-transformation.html"><span class="header-section-number">19</span> review sheet for r code and data transformation</a></li>
<li><a class="" href="scrape-twitter-data-using-r.html"><span class="header-section-number">20</span> Scrape Twitter data using R</a></li>
<li><a class="" href="r-note-and-mathematics-in-rmd-cheatsheet.html"><span class="header-section-number">21</span> R note and Mathematics in Rmd cheatsheet</a></li>
<li><a class="" href="textbook-notes.html"><span class="header-section-number">22</span> Textbook Notes</a></li>
<li><a class="" href="ggplot2-cheatsheet.html"><span class="header-section-number">23</span> ggplot2 cheatsheet</a></li>
<li><a class="" href="rstudio-cheatsheet.html"><span class="header-section-number">24</span> RStudio Cheatsheet</a></li>
<li><a class="" href="d3-visualization-in-r-cheatsheet.html"><span class="header-section-number">25</span> D3 Visualization in R Cheatsheet</a></li>
<li><a class="" href="colors.html"><span class="header-section-number">26</span> Colors</a></li>
<li class="book-part">Tutorials</li>
<li><a class="active" href="tutorial-on-cluster-analysis.html"><span class="header-section-number">27</span> Tutorial on Cluster Analysis</a></li>
<li><a class="" href="how-to-integrate-r-with-postgresql.html"><span class="header-section-number">28</span> How to Integrate R with PostgreSQL</a></li>
<li><a class="" href="apply-function-in-r.html"><span class="header-section-number">29</span> Apply function in r</a></li>
<li><a class="" href="introduction-to-interactive-graphs-in-r.html"><span class="header-section-number">30</span> Introduction to interactive graphs in R</a></li>
<li><a class="" href="plot-and-analyze-stock-data-with-r.html"><span class="header-section-number">31</span> Plot and Analyze Stock Data with R</a></li>
<li><a class="" href="data-visulization-ordering.html"><span class="header-section-number">32</span> Data Visulization Ordering</a></li>
<li><a class="" href="tutorial-on-lattice-package-in-r.html"><span class="header-section-number">33</span> Tutorial on lattice package in R</a></li>
<li><a class="" href="network-visualization-in-r.html"><span class="header-section-number">34</span> Network Visualization in R</a></li>
<li><a class="" href="dplyr-tutorial-in-r.html"><span class="header-section-number">35</span> Dplyr tutorial in R</a></li>
<li><a class="" href="downloading-files.html"><span class="header-section-number">36</span> Downloading files</a></li>
<li><a class="" href="video-introduction-to-maps-with-ggmap.html"><span class="header-section-number">37</span> Video introduction to maps with ggmap</a></li>
<li><a class="" href="comparison-among-base-r-tidyverse-and-datatable.html"><span class="header-section-number">38</span> Comparison among base R, tidyverse, and datatable</a></li>
<li><a class="" href="raincloud-plot-101-density-plot-or-boxplotwhy-not-do-both.html"><span class="header-section-number">39</span> Raincloud plot 101: density plot or boxplot？Why not do both!</a></li>
<li><a class="" href="an-introduction-to-dygraph-in-r.html"><span class="header-section-number">40</span> An Introduction to Dygraph in R</a></li>
<li><a class="" href="streamlit-tutorial.html"><span class="header-section-number">41</span> Streamlit Tutorial</a></li>
<li><a class="" href="hive-plots-with-the-ggraph-and-hiver-packages.html"><span class="header-section-number">42</span> Hive plots with the ggraph and hiver packages</a></li>
<li><a class="" href="introduction-to-xai-explainable-ai-in-r.html"><span class="header-section-number">43</span> Introduction to XAI (Explainable AI) in R</a></li>
<li><a class="" href="tutorial-for-gg_cleveland.html"><span class="header-section-number">44</span> Tutorial for gg_cleveland</a></li>
<li><a class="" href="neural-network-tools-in-r.html"><span class="header-section-number">45</span> Neural network tools in R</a></li>
<li><a class="" href="r-dplyr-vs-python-pandas.html"><span class="header-section-number">46</span> R Dplyr vs Python Pandas</a></li>
<li><a class="" href="readable-plots.html"><span class="header-section-number">47</span> Readable Plots</a></li>
<li><a class="" href="introduction-to-exploratory-spatial-data-analysis-and-visualization-using-qgis.html"><span class="header-section-number">48</span> Introduction to exploratory spatial data analysis and visualization using QGIS</a></li>
<li><a class="" href="data-visualization-in-python-vs-r.html"><span class="header-section-number">49</span> Data Visualization in Python vs R</a></li>
<li><a class="" href="base-r-tutorial.html"><span class="header-section-number">50</span> Base R Tutorial</a></li>
<li><a class="" href="python-altair-visualization-method-tutorial.html"><span class="header-section-number">51</span> Python Altair Visualization Method Tutorial</a></li>
<li><a class="" href="r-to-python-easy-plot.html"><span class="header-section-number">52</span> R to python easy plot</a></li>
<li><a class="" href="introduction-to-models-and-prediction-evaluation.html"><span class="header-section-number">53</span> Introduction to models and prediction evaluation</a></li>
<li><a class="" href="introduction-to-interactive-time-series-visualizations-with-dygraphs-in-r.html"><span class="header-section-number">54</span> Introduction to Interactive Time Series Visualizations with dygraphs in R</a></li>
<li><a class="" href="integrate-r-with-python.html"><span class="header-section-number">55</span> Integrate R with Python</a></li>
<li><a class="" href="python-visualization-tutorial.html"><span class="header-section-number">56</span> Python Visualization Tutorial</a></li>
<li><a class="" href="gganimate-tutorial.html"><span class="header-section-number">57</span> Gganimate Tutorial</a></li>
<li><a class="" href="get-nba-dataset-in-r.html"><span class="header-section-number">58</span> Get NBA dataset in R</a></li>
<li><a class="" href="mtemplates.html"><span class="header-section-number">59</span> Mtemplates</a></li>
<li><a class="" href="introduction-to-time-series-analysis-in-r.html"><span class="header-section-number">60</span> Introduction to Time Series Analysis in R</a></li>
<li><a class="" href="storytelling-with-data.html"><span class="header-section-number">61</span> Storytelling with Data</a></li>
<li><a class="" href="tutorial-on-r-torch-package.html"><span class="header-section-number">62</span> Tutorial on R torch package</a></li>
<li><a class="" href="edav-tutorials-correlogram-calendar-heatmap-and-slopegram.html"><span class="header-section-number">63</span> EDAV Tutorials: Correlogram, Calendar Heatmap and Slopegram</a></li>
<li><a class="" href="recursive-codes-and-self-organized-map-with-r.html"><span class="header-section-number">64</span> Recursive codes and self-organized map with R</a></li>
<li><a class="" href="tutorial-of-three-ggplot2-based-packages.html"><span class="header-section-number">65</span> Tutorial of three ggplot2 based packages</a></li>
<li><a class="" href="a-step-by-step-tutorial-for-natural-language-processing-in-r.html"><span class="header-section-number">66</span> A Step by Step Tutorial for Natural Language Processing in R</a></li>
<li class="book-part">Project &amp; Workshops</li>
<li><a class="" href="introduction-to-analytics-consulting-at-accenture.html"><span class="header-section-number">67</span> Introduction to analytics consulting at Accenture</a></li>
<li><a class="" href="map-of-the-r-world.html"><span class="header-section-number">68</span> Map of the R world</a></li>
<li><a class="" href="alluvial-diagrams-and-their-implementation-using-ggalluvial-in-r.html"><span class="header-section-number">69</span> Alluvial diagrams and their implementation using GGalluvial in R</a></li>
<li class="book-part">Data Visualization</li>
<li><a class="" href="an-introduction-to-pyecharts-package-in-python.html"><span class="header-section-number">70</span> An introduction to pyecharts package in Python</a></li>
<li><a class="" href="visualization-in-r-v.s.-python.html"><span class="header-section-number">71</span> Visualization in R v.s. Python</a></li>
<li><a class="" href="understand-data-with-plots.html"><span class="header-section-number">72</span> Understand data with plots</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="github-initial-setup.html"><span class="header-section-number">73</span> Github initial setup</a></li>
<li><a class="" href="tutorial-for-pull-request-mergers.html"><span class="header-section-number">74</span> Tutorial for pull request mergers</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jtr13/cc21fall2">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="tutorial-on-cluster-analysis" class="section level1">
<h1>
<span class="header-section-number">27</span> Tutorial on Cluster Analysis<a class="anchor" aria-label="anchor" href="#tutorial-on-cluster-analysis"><i class="fas fa-link"></i></a>
</h1>
<p>Jannik Wiedenhaupt</p>
<div id="what-is-clustering-analysis" class="section level2">
<h2>
<span class="header-section-number">27.1</span> What is Clustering Analysis?<a class="anchor" aria-label="anchor" href="#what-is-clustering-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>Clustering Analysis is a data exploration method and one of the most popular classification techniques. Clustering works by segregating data points into different groups based on the similarity and dissimiliarity of attributes. That means data is clustered such that the homogeneity inside the clusters is maximized and the heterogeneity between the clusters maximized. For any concept that is novel to human understanding, clustering or grouping elements based on their likeness is important.</p>
<p>Likewise in data science and machine learning, clustering algorithms carry out the task of labeling unlabelled data inputs which further helps in data interpretation and establishing patterns for predictive purposes.</p>
<p>To understand the idea of clustering, let’s look at the following picures where the points are customer who rated their personal importance of price and quality.</p>
<div align="center">
<p align="center">
<strong>Can we identify any groups of data points in this graph?</strong>
</p>
<div align="center" class="inline-figure">
<img src="resources/clustering_analysis_tutorial/Clustering0.jpg" alt="Cluster0" width="300" align="middle">
</div>
<p align="center">
<strong>Should we cluster the data like this?</strong>
</p>
<div align="center" class="inline-figure">
<img src="resources/clustering_analysis_tutorial/Clustering1.jpg" alt="Cluster1" width="300" align="middle">
</div>
<p align="center">
<strong>Or like this?</strong>
</p>
<div align="center" class="inline-figure">
<img src="resources/clustering_analysis_tutorial/Clustering2.jpg" alt="Cluster2" width="300" align="middle">
</div>
</div>
<p>From the visual representation (which are also only two-dimensional), we can already not clearly decide how to cluster the data points. To cluster data points properly, we need clustering algorithms.</p>
</div>
<div id="what-types-of-clustering-analysis-exist" class="section level2">
<h2>
<span class="header-section-number">27.2</span> What Types of Clustering Analysis Exist?<a class="anchor" aria-label="anchor" href="#what-types-of-clustering-analysis-exist"><i class="fas fa-link"></i></a>
</h2>
<p>There are many different types of clustering algorithms that are particularly useful for different situations.</p>
<p>The four most common types are:</p>
<div id="centroid-based-algorithms" class="section level3">
<h3>
<span class="header-section-number">27.2.1</span> Centroid-based Algorithms<a class="anchor" aria-label="anchor" href="#centroid-based-algorithms"><i class="fas fa-link"></i></a>
</h3>
<p>Centroid-based algorithm separate data points based on multiple so-called centroids in the data. Each data point is assigned to a cluster based on its squared distance from the centroid. This is the most commonly used type of clustering.</p>
</div>
<div id="hierarchical-algorithms" class="section level3">
<h3>
<span class="header-section-number">27.2.2</span> Hierarchical Algorithms<a class="anchor" aria-label="anchor" href="#hierarchical-algorithms"><i class="fas fa-link"></i></a>
</h3>
<p>Hierarchical algorithms differ from centroid-based algorithms in that they constract a hierarchy among all data points. From this hierarchy, one can choose different sized clusters based on the granularity required for the task at hand. This is normally used on hierarchical data structures like company databases or a taxonomy of animal species.
There are two main types of hierarchical algorithms:</p>
<ol style="list-style-type: decimal">
<li>Agglomerative clustering - all observations are considered invdividually and then merged into everbigger clusters</li>
<li>Divisive cluster - all observations are considered together and then split up int eversmaller clusters</li>
</ol>
</div>
<div id="distribution-based-algorithms" class="section level3">
<h3>
<span class="header-section-number">27.2.3</span> Distribution-based Algorithms<a class="anchor" aria-label="anchor" href="#distribution-based-algorithms"><i class="fas fa-link"></i></a>
</h3>
<p>Distribution-based clustering assumes data is composed of distributions. Therefore, all data points are considered parts of a cluster based on the probability that they belong to a given cluster. As distance from the center of a cluster increases, the probability that the data point belongs to that cluster decreases. This algorithm is only recommended when you know the distribution of your data.</p>
</div>
<div id="density-based-algorithms" class="section level3">
<h3>
<span class="header-section-number">27.2.4</span> Density-based Algorithms<a class="anchor" aria-label="anchor" href="#density-based-algorithms"><i class="fas fa-link"></i></a>
</h3>
<p>Density-based clustering works by detecting regions in which factors are focused and in which they’re separated via means of regions that might be empty or sparse. Points that are not a part of a cluster are categorized as noise. Outliers are not assigned to clusters and therefore ignored in these algorithms.</p>
</div>
</div>
<div id="how-does-cluster-analysis-work-on-paper" class="section level2">
<h2>
<span class="header-section-number">27.3</span> How Does Cluster Analysis Work on Paper?<a class="anchor" aria-label="anchor" href="#how-does-cluster-analysis-work-on-paper"><i class="fas fa-link"></i></a>
</h2>
<p>The following process should be followed when approaching a cluster analysis.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Variable selection:</strong> Select the variables, called <em>bases</em>, that will be used to cluster the observations. If you want to make any decisions based on the classification, for example in targeting different groups of customers, you most likely also want to have additional variables, called <em>descriptors</em>, that help you understand the found clusters.</li>
<li>
<strong>Similarity/Dissimilarity calculation:</strong> Choose a suitable measures of proximity between the different observations. Based on the type of the bases, you need to choose a <em>distance function</em> or a <em>similarity function</em>. The variables are compared individually first. Then, they are summed up to calculate the total similarity/distance between two observations. Comparing all observations with each other yields a <em>proximity or distance matrix</em>.</li>
<li>
<strong>Cluster creation:</strong> Choose a suitable clustering method from the ones mentioned above and if needed also an objective functions to decide when clusters are merged or split up.</li>
</ol>
<p><strong>Additional steps (not always required):</strong>
1. Determine the number of clusters. This can be either done based on a thorough understanding of the problem’s domain, the planned interpretation, or a statistical procedure. This is for example required for centroid-based algorithms.
2. Interpretation of the clusters.
3. Test the strength of the clustering results. Test the internal homogeneity and external homogeneity of the clusters.</p>
</div>
<div id="how-does-cluster-analysis-work-in-r" class="section level2">
<h2>
<span class="header-section-number">27.4</span> How Does Cluster Analysis Work in R?<a class="anchor" aria-label="anchor" href="#how-does-cluster-analysis-work-in-r"><i class="fas fa-link"></i></a>
</h2>
<div id="data-preparation" class="section level3">
<h3>
<span class="header-section-number">27.4.1</span> Data Preparation<a class="anchor" aria-label="anchor" href="#data-preparation"><i class="fas fa-link"></i></a>
</h3>
<p>First, we load in the dataset. In this tutorial, we use the <em>states</em> dataset to cluster US states.</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">datasets</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/r/datasets/state.html">state.x77</a></span><span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p>Second, we will also use the <em>factoextra</em> package and particularly the <em>eclust</em> function to simplify the analysis and visualization.</p>
<p>Third, we check that the data has the following form:</p>
<ol style="list-style-type: decimal">
<li>Rows are observations and columns are variables</li>
<li>Missing values are removed or estimated</li>
<li>Data must be standardized</li>
<li>Avoid double-weighting of underlying constructs by avoiding multicollinearity</li>
</ol>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">df</span>, <span class="fl">3</span><span class="op">)</span></code></pre></div>
<pre><code>##         Population Income Illiteracy Life.Exp Murder HS.Grad Frost   Area
## Alabama       3615   3624        2.1    69.05   15.1    41.3    20  50708
## Alaska         365   6315        1.5    69.31   11.3    66.7   152 566432
## Arizona       2212   4530        1.8    70.55    7.8    58.1    15 113417</code></pre>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Delete NA values</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>

<span class="co"># Save non-scaled version for later</span>
<span class="va">df_original</span> <span class="op">&lt;-</span> <span class="va">df</span>

<span class="co"># Standardize variables</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html">mutate_all</a></span><span class="op">(</span><span class="op">~</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">as.vector</span><span class="op">)</span><span class="op">)</span>

<span class="va">cor_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="fu">corrplot</span><span class="op">(</span><span class="va">cor_matrix</span>, method <span class="op">=</span> <span class="st">"number"</span>, type <span class="op">=</span> <span class="st">"lower"</span>, tl.pos <span class="op">=</span> <span class="st">'d'</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-4-1.png" width="960" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Because murder and life expectancy are strongly correlated, we remove murder</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">df</span>, select <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">Murder</span><span class="op">)</span><span class="op">)</span></code></pre></div>
</div>
<div id="centroid-based-algorithms-1" class="section level3">
<h3>
<span class="header-section-number">27.4.2</span> Centroid-based Algorithms<a class="anchor" aria-label="anchor" href="#centroid-based-algorithms-1"><i class="fas fa-link"></i></a>
</h3>
<p>The classic centroid-based algorithm is called “k-means” and will be used here. K-means takes data points as input and groups them into <em>k</em> clusters through the following process.</p>
<ol style="list-style-type: decimal">
<li>Select inputs</li>
<li>Select <em>k</em> cluster centers</li>
<li>Assign cases to closest center</li>
<li>Update cluster centers</li>
<li>Reassign cases</li>
<li>Repeat steps 4 and 5 until convergence</li>
</ol>
<p>Going through this process in R is very simple as it only requires one function.
The parameters are the following</p>
<ul>
<li>
<strong>FUNcluster:</strong> Clustering function. Here, k-means.</li>
<li>
<strong>hc_metric:</strong> Metric to be used for calculating dissimilarities between observations. Here, euclidean distance.</li>
<li>
<strong>k:</strong> Number of clusters. Here 5 is guessed because of the lack of further exploration of the dataset.</li>
</ul>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.km</span> <span class="op">&lt;-</span> <span class="fu">eclust</span><span class="op">(</span><span class="va">df</span>, FUNcluster <span class="op">=</span> <span class="st">"kmeans"</span>, k <span class="op">=</span> <span class="fl">5</span>, hc_metric <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-5-1.png" width="960" style="display: block; margin: auto;"></div>
<div id="choosing-the-number-of-clusters" class="section level4">
<h4>
<span class="header-section-number">27.4.2.1</span> Choosing the Number of Clusters<a class="anchor" aria-label="anchor" href="#choosing-the-number-of-clusters"><i class="fas fa-link"></i></a>
</h4>
<p>Alternatively to setting the number of clusters <em>k</em> ourselves, we can also resort to different statistics:</p>
<p><strong>1. Gap Statistic</strong></p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.km</span> <span class="op">&lt;-</span> <span class="fu">eclust</span><span class="op">(</span><span class="va">df</span>, FUNcluster <span class="op">=</span> <span class="st">"kmeans"</span>, hc_metric <span class="op">=</span> <span class="st">"euclidean"</span>, graph <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu">fviz_gap_stat</span><span class="op">(</span><span class="va">res.km</span><span class="op">$</span><span class="va">gap_stat</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-6-1.png" width="960" style="display: block; margin: auto;"></div>
<p><strong>2. Silhouette Plot</strong></p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">fviz_silhouette</span><span class="op">(</span><span class="va">res.km</span><span class="op">)</span></code></pre></div>
<pre><code>##   cluster size ave.sil.width
## 1       1   15          0.08
## 2       2   23          0.36
## 3       3   11          0.52
## 4       4    1          0.00</code></pre>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-7-1.png" width="960" style="display: block; margin: auto;"></div>
<p><strong>3. Elbow Method</strong>
The elbow method is a visual method, where we determine the cluster based on spotting an elbow in the graph.</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">fviz_nbclust</span><span class="op">(</span><span class="va">df</span>, FUNcluster <span class="op">=</span> <span class="va">kmeans</span>, method <span class="op">=</span> <span class="st">"wss"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">"Elbow method"</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-8-1.png" width="960" style="display: block; margin: auto;"></div>
<p>There are weak (not very pronounced) elbows at 2 and 6.</p>
<p><strong>4. Other Indices</strong>
Use the package <em>NbClust</em> to experiment with different clustering methods, distances, and indices.</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"C-Index:\n"</span>, <span class="fu">NbClust</span><span class="op">(</span>data<span class="op">=</span><span class="va">df</span>, method <span class="op">=</span> <span class="st">"kmeans"</span>, distance <span class="op">=</span> <span class="st">"euclidean"</span>, index<span class="op">=</span><span class="st">"cindex"</span><span class="op">)</span><span class="op">$</span><span class="va">Best.nc</span><span class="op">)</span></code></pre></div>
<pre><code>## C-Index:
##  3 0.2594</code></pre>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Dunn-Index:\n"</span>, <span class="fu">NbClust</span><span class="op">(</span>data<span class="op">=</span><span class="va">df</span>, method <span class="op">=</span> <span class="st">"kmeans"</span>, distance <span class="op">=</span> <span class="st">"euclidean"</span>, index<span class="op">=</span><span class="st">"dunn"</span><span class="op">)</span><span class="op">$</span><span class="va">Best.nc</span><span class="op">)</span></code></pre></div>
<pre><code>## Dunn-Index:
##  15 0.3403</code></pre>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"McClain-Index:\n"</span>, <span class="fu">NbClust</span><span class="op">(</span>data<span class="op">=</span><span class="va">df</span>, method <span class="op">=</span> <span class="st">"kmeans"</span>, distance <span class="op">=</span> <span class="st">"euclidean"</span>, index<span class="op">=</span><span class="st">"mcclain"</span><span class="op">)</span><span class="op">$</span><span class="va">Best.nc</span><span class="op">)</span></code></pre></div>
<pre><code>## McClain-Index:
##  2 0.3932</code></pre>
</div>
</div>
<div id="hierarchial-algorithms" class="section level3">
<h3>
<span class="header-section-number">27.4.3</span> Hierarchial Algorithms<a class="anchor" aria-label="anchor" href="#hierarchial-algorithms"><i class="fas fa-link"></i></a>
</h3>
<p>There are two fundamental methods of hierarchical clustering - agglomerative and divisive clustering. We will explain both.
In hierarchical clustering you do not need to define or calculate the number of clusters before running the algorithm. Moreover, hierarchical clustering results in a comprehensible tree-like structure called a <em>Dendrogram</em> that allows us to find the number of clusters that is most interpretable.</p>
<div id="divisive-hierarchical-clustering" class="section level4">
<h4>
<span class="header-section-number">27.4.3.1</span> Divisive Hierarchical Clustering<a class="anchor" aria-label="anchor" href="#divisive-hierarchical-clustering"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>All objects or points in the dataset belong to one single cluster</li>
<li>Partition the single cluster into the two least similar clusters</li>
<li>Repeat step 2 until each observation is a single cluster</li>
</ol>
<p>The parameters are the following</p>
<ul>
<li>
<strong>FUNcluster:</strong> “hclust” for divisive clustering.</li>
<li>
<strong>hc_metric:</strong> “euclidean” for euclidean distance.</li>
</ul>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.hclust</span> <span class="op">&lt;-</span> <span class="fu">eclust</span><span class="op">(</span><span class="va">df</span>, FUNcluster <span class="op">=</span> <span class="st">"hclust"</span>, hc_metric <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span>
<span class="fu">fviz_dend</span><span class="op">(</span><span class="va">res.hclust</span>, rect <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-10-1.png" width="960" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">fviz_cluster</span><span class="op">(</span><span class="va">res.hclust</span>, labelsize <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-11-1.png" width="960" style="display: block; margin: auto;"></div>
<p>Here, we see a discrepancy to k-means clustering. While the gap-statistic yielded 4 optimal clusters, the hierarchical clustering identifies 2 major cluster.</p>
</div>
<div id="agglomerative-hierarchical-clustering" class="section level4">
<h4>
<span class="header-section-number">27.4.3.2</span> Agglomerative Hierarchical Clustering<a class="anchor" aria-label="anchor" href="#agglomerative-hierarchical-clustering"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>Each observation is a single cluster</li>
<li>Every two observations that are closest to each other according to the distance measure, are clustered</li>
<li>Repeat step 2 until all observations are one cluster</li>
</ol>
<p>It is important to notice that agglomerative clustering requires a agglomeration method to be specified. There are different agglomeration methods on which you can read up here: <a href="https://en.wikipedia.org/wiki/Hierarchical_clustering#Linkage_criteria" class="uri">https://en.wikipedia.org/wiki/Hierarchical_clustering#Linkage_criteria</a>.
We choose the commonly used ward.D2 measure that minimized total within-cluster variance.</p>
<p>The parameters are the following</p>
<ul>
<li>
<strong>FUNcluster:</strong> “agnes” for agglomerative nesting.</li>
<li>
<strong>hc_method:</strong> Agglomeration method. Here, ward.D2.</li>
<li>
<strong>hc_metric:</strong> “euclidean” for euclidean distance.</li>
</ul>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.aclust</span> <span class="op">&lt;-</span> <span class="fu">eclust</span><span class="op">(</span><span class="va">df</span>, FUNcluster <span class="op">=</span> <span class="st">"hclust"</span>, hc_metric <span class="op">=</span> <span class="st">"euclidean"</span>, hc_method <span class="op">=</span> <span class="st">"ward.D2"</span><span class="op">)</span>
<span class="fu">fviz_dend</span><span class="op">(</span><span class="va">res.aclust</span>, rect <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-12-1.png" width="960" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">fviz_cluster</span><span class="op">(</span><span class="va">res.aclust</span>, labelsize <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-13-1.png" width="960" style="display: block; margin: auto;"></div>
<p>While it is possible to see differences between agglomerative and diviseve clustering, the two methods come to the same result in this example.</p>
</div>
</div>
<div id="distribution-based-algorithms-1" class="section level3">
<h3>
<span class="header-section-number">27.4.4</span> Distribution-based Algorithms<a class="anchor" aria-label="anchor" href="#distribution-based-algorithms-1"><i class="fas fa-link"></i></a>
</h3>
<p>For an explanation and very good R-tutorial on distribution-based algorithms, please visit (Note: Distribution-based algorithms are called model-based algorithms here): <a href="https://www.datanovia.com/en/lessons/model-based-clustering-essentials/" class="uri">https://www.datanovia.com/en/lessons/model-based-clustering-essentials/</a></p>
</div>
<div id="density-based-algorithms-1" class="section level3">
<h3>
<span class="header-section-number">27.4.5</span> Density-based Algorithms<a class="anchor" aria-label="anchor" href="#density-based-algorithms-1"><i class="fas fa-link"></i></a>
</h3>
<p>For an explanation and very good R-tutorial on density-based algorithms, please visit: <a href="https://www.datanovia.com/en/lessons/dbscan-density-based-clustering-essentials/" class="uri">https://www.datanovia.com/en/lessons/dbscan-density-based-clustering-essentials/</a></p>
</div>
</div>
<div id="using-clustering-for-further-analysis" class="section level2">
<h2>
<span class="header-section-number">27.5</span> Using Clustering for Further Analysis<a class="anchor" aria-label="anchor" href="#using-clustering-for-further-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>After clustering your observations, we want to understand what the clusters mean. To do this, we will visualize the average strenght of each variable in each cluster.</p>
<p>First, assign the clusters to the dataframe.</p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df_clusters</span> <span class="op">&lt;-</span> <span class="va">res.km</span><span class="op">$</span><span class="va">centers</span></code></pre></div>
<p>(Output of res.km is the following)</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.km</span></code></pre></div>
<pre><code>## K-means clustering with 4 clusters of sizes 15, 23, 11, 1
## 
## Cluster means:
##   Population      Income  Illiteracy    Life.Exp    HS.Grad      Frost
## 1  1.0136832  0.61841919  0.09296733  0.07901309  0.1822459 -0.5975278
## 2 -0.5147347  0.08615414 -0.74968285  0.56233752  0.4850920  0.6945869
## 3 -0.2269956 -1.30146170  1.39152706 -1.17731360 -1.4157826 -0.7206500
## 4 -0.8693980  3.05824562  0.54139799 -1.16850978  1.6828035  0.9145676
##          Area
## 1 -0.07085360
## 2 -0.09444464
## 3 -0.23402899
## 4  5.80934967
## 
## Clustering vector:
##        Alabama         Alaska        Arizona       Arkansas     California 
##              3              4              1              3              1 
##       Colorado    Connecticut       Delaware        Florida        Georgia 
##              2              2              2              1              3 
##         Hawaii          Idaho       Illinois        Indiana           Iowa 
##              1              2              1              2              2 
##         Kansas       Kentucky      Louisiana          Maine       Maryland 
##              2              3              3              2              1 
##  Massachusetts       Michigan      Minnesota    Mississippi       Missouri 
##              1              1              2              3              2 
##        Montana       Nebraska         Nevada  New Hampshire     New Jersey 
##              2              2              2              2              1 
##     New Mexico       New York North Carolina   North Dakota           Ohio 
##              3              1              3              2              1 
##       Oklahoma         Oregon   Pennsylvania   Rhode Island South Carolina 
##              2              2              1              2              3 
##   South Dakota      Tennessee          Texas           Utah        Vermont 
##              2              3              1              2              2 
##       Virginia     Washington  West Virginia      Wisconsin        Wyoming 
##              1              1              3              2              2 
## 
## Within cluster sum of squares by cluster:
## [1] 66.96776 52.45135 19.80725  0.00000
##  (between_SS / total_SS =  59.4 %)
## 
## Available components:
## 
##  [1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
##  [6] "betweenss"    "size"         "iter"         "ifault"       "silinfo"     
## [11] "nbclust"      "data"         "gap_stat"</code></pre>
<p>Second, visualize the strength of the variables using a heatmap to describe the different clusters.</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">melt_df</span> <span class="op">&lt;-</span> <span class="fu">melt</span><span class="op">(</span><span class="va">df_clusters</span><span class="op">)</span>

<span class="va">heatmap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">melt_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Var2</span>, <span class="va">Var1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_colour_continuous.html">scale_fill_continuous</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"viridis"</span>, direction <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_tile</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">value</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Strength of Each of the Variables in the Clusters"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Variable"</span>, y<span class="op">=</span><span class="st">"Cluster"</span><span class="op">)</span>
<span class="va">heatmap</span></code></pre></div>
<div class="inline-figure"><img src="clustering_analysis_tutorial_files/figure-html/unnamed-chunk-16-1.png" width="960" style="display: block; margin: auto;"></div>
<p>The clustering of the variables shows that cluster 4 has the largest area and above average income. However, it comprises only one observation and is thus less interpretable. Cluster 3 has below average income, life expectancy and highschool graduation, but above average illiteracy. This cluster can be seen as one of worse performing states in these developmental areas. Cluster 2 and 1 are relatively similar with mostly average characteristics. The most meaningful difference is the population. Therefore, we could call cluster 2 “Low-populated average states” and cluster 2 “High-populated average states”.</p>
<p>Here we see the final classification results again:</p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df_original</span><span class="op">[</span><span class="st">"Cluster"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">res.km</span><span class="op">$</span><span class="va">cluster</span>
<span class="va">df_out</span> <span class="op">&lt;-</span> <span class="va">df_original</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html">order</a></span><span class="op">(</span><span class="op">-</span><span class="va">df_original</span><span class="op">$</span><span class="va">Cluster</span><span class="op">)</span>, <span class="op">]</span>
<span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="va">df_out</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left"></th>
<th align="right">Population</th>
<th align="right">Income</th>
<th align="right">Illiteracy</th>
<th align="right">Life.Exp</th>
<th align="right">Murder</th>
<th align="right">HS.Grad</th>
<th align="right">Frost</th>
<th align="right">Area</th>
<th align="right">Cluster</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Alaska</td>
<td align="right">365</td>
<td align="right">6315</td>
<td align="right">1.5</td>
<td align="right">69.31</td>
<td align="right">11.3</td>
<td align="right">66.7</td>
<td align="right">152</td>
<td align="right">566432</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">Alabama</td>
<td align="right">3615</td>
<td align="right">3624</td>
<td align="right">2.1</td>
<td align="right">69.05</td>
<td align="right">15.1</td>
<td align="right">41.3</td>
<td align="right">20</td>
<td align="right">50708</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Arkansas</td>
<td align="right">2110</td>
<td align="right">3378</td>
<td align="right">1.9</td>
<td align="right">70.66</td>
<td align="right">10.1</td>
<td align="right">39.9</td>
<td align="right">65</td>
<td align="right">51945</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Georgia</td>
<td align="right">4931</td>
<td align="right">4091</td>
<td align="right">2.0</td>
<td align="right">68.54</td>
<td align="right">13.9</td>
<td align="right">40.6</td>
<td align="right">60</td>
<td align="right">58073</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Kentucky</td>
<td align="right">3387</td>
<td align="right">3712</td>
<td align="right">1.6</td>
<td align="right">70.10</td>
<td align="right">10.6</td>
<td align="right">38.5</td>
<td align="right">95</td>
<td align="right">39650</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Louisiana</td>
<td align="right">3806</td>
<td align="right">3545</td>
<td align="right">2.8</td>
<td align="right">68.76</td>
<td align="right">13.2</td>
<td align="right">42.2</td>
<td align="right">12</td>
<td align="right">44930</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Mississippi</td>
<td align="right">2341</td>
<td align="right">3098</td>
<td align="right">2.4</td>
<td align="right">68.09</td>
<td align="right">12.5</td>
<td align="right">41.0</td>
<td align="right">50</td>
<td align="right">47296</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">New Mexico</td>
<td align="right">1144</td>
<td align="right">3601</td>
<td align="right">2.2</td>
<td align="right">70.32</td>
<td align="right">9.7</td>
<td align="right">55.2</td>
<td align="right">120</td>
<td align="right">121412</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">North Carolina</td>
<td align="right">5441</td>
<td align="right">3875</td>
<td align="right">1.8</td>
<td align="right">69.21</td>
<td align="right">11.1</td>
<td align="right">38.5</td>
<td align="right">80</td>
<td align="right">48798</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">South Carolina</td>
<td align="right">2816</td>
<td align="right">3635</td>
<td align="right">2.3</td>
<td align="right">67.96</td>
<td align="right">11.6</td>
<td align="right">37.8</td>
<td align="right">65</td>
<td align="right">30225</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Tennessee</td>
<td align="right">4173</td>
<td align="right">3821</td>
<td align="right">1.7</td>
<td align="right">70.11</td>
<td align="right">11.0</td>
<td align="right">41.8</td>
<td align="right">70</td>
<td align="right">41328</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">West Virginia</td>
<td align="right">1799</td>
<td align="right">3617</td>
<td align="right">1.4</td>
<td align="right">69.48</td>
<td align="right">6.7</td>
<td align="right">41.6</td>
<td align="right">100</td>
<td align="right">24070</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Colorado</td>
<td align="right">2541</td>
<td align="right">4884</td>
<td align="right">0.7</td>
<td align="right">72.06</td>
<td align="right">6.8</td>
<td align="right">63.9</td>
<td align="right">166</td>
<td align="right">103766</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Connecticut</td>
<td align="right">3100</td>
<td align="right">5348</td>
<td align="right">1.1</td>
<td align="right">72.48</td>
<td align="right">3.1</td>
<td align="right">56.0</td>
<td align="right">139</td>
<td align="right">4862</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Delaware</td>
<td align="right">579</td>
<td align="right">4809</td>
<td align="right">0.9</td>
<td align="right">70.06</td>
<td align="right">6.2</td>
<td align="right">54.6</td>
<td align="right">103</td>
<td align="right">1982</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Idaho</td>
<td align="right">813</td>
<td align="right">4119</td>
<td align="right">0.6</td>
<td align="right">71.87</td>
<td align="right">5.3</td>
<td align="right">59.5</td>
<td align="right">126</td>
<td align="right">82677</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Indiana</td>
<td align="right">5313</td>
<td align="right">4458</td>
<td align="right">0.7</td>
<td align="right">70.88</td>
<td align="right">7.1</td>
<td align="right">52.9</td>
<td align="right">122</td>
<td align="right">36097</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Iowa</td>
<td align="right">2861</td>
<td align="right">4628</td>
<td align="right">0.5</td>
<td align="right">72.56</td>
<td align="right">2.3</td>
<td align="right">59.0</td>
<td align="right">140</td>
<td align="right">55941</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Kansas</td>
<td align="right">2280</td>
<td align="right">4669</td>
<td align="right">0.6</td>
<td align="right">72.58</td>
<td align="right">4.5</td>
<td align="right">59.9</td>
<td align="right">114</td>
<td align="right">81787</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Maine</td>
<td align="right">1058</td>
<td align="right">3694</td>
<td align="right">0.7</td>
<td align="right">70.39</td>
<td align="right">2.7</td>
<td align="right">54.7</td>
<td align="right">161</td>
<td align="right">30920</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Minnesota</td>
<td align="right">3921</td>
<td align="right">4675</td>
<td align="right">0.6</td>
<td align="right">72.96</td>
<td align="right">2.3</td>
<td align="right">57.6</td>
<td align="right">160</td>
<td align="right">79289</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Missouri</td>
<td align="right">4767</td>
<td align="right">4254</td>
<td align="right">0.8</td>
<td align="right">70.69</td>
<td align="right">9.3</td>
<td align="right">48.8</td>
<td align="right">108</td>
<td align="right">68995</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Montana</td>
<td align="right">746</td>
<td align="right">4347</td>
<td align="right">0.6</td>
<td align="right">70.56</td>
<td align="right">5.0</td>
<td align="right">59.2</td>
<td align="right">155</td>
<td align="right">145587</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Nebraska</td>
<td align="right">1544</td>
<td align="right">4508</td>
<td align="right">0.6</td>
<td align="right">72.60</td>
<td align="right">2.9</td>
<td align="right">59.3</td>
<td align="right">139</td>
<td align="right">76483</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Nevada</td>
<td align="right">590</td>
<td align="right">5149</td>
<td align="right">0.5</td>
<td align="right">69.03</td>
<td align="right">11.5</td>
<td align="right">65.2</td>
<td align="right">188</td>
<td align="right">109889</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">New Hampshire</td>
<td align="right">812</td>
<td align="right">4281</td>
<td align="right">0.7</td>
<td align="right">71.23</td>
<td align="right">3.3</td>
<td align="right">57.6</td>
<td align="right">174</td>
<td align="right">9027</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">North Dakota</td>
<td align="right">637</td>
<td align="right">5087</td>
<td align="right">0.8</td>
<td align="right">72.78</td>
<td align="right">1.4</td>
<td align="right">50.3</td>
<td align="right">186</td>
<td align="right">69273</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Oklahoma</td>
<td align="right">2715</td>
<td align="right">3983</td>
<td align="right">1.1</td>
<td align="right">71.42</td>
<td align="right">6.4</td>
<td align="right">51.6</td>
<td align="right">82</td>
<td align="right">68782</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Oregon</td>
<td align="right">2284</td>
<td align="right">4660</td>
<td align="right">0.6</td>
<td align="right">72.13</td>
<td align="right">4.2</td>
<td align="right">60.0</td>
<td align="right">44</td>
<td align="right">96184</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Rhode Island</td>
<td align="right">931</td>
<td align="right">4558</td>
<td align="right">1.3</td>
<td align="right">71.90</td>
<td align="right">2.4</td>
<td align="right">46.4</td>
<td align="right">127</td>
<td align="right">1049</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">South Dakota</td>
<td align="right">681</td>
<td align="right">4167</td>
<td align="right">0.5</td>
<td align="right">72.08</td>
<td align="right">1.7</td>
<td align="right">53.3</td>
<td align="right">172</td>
<td align="right">75955</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Utah</td>
<td align="right">1203</td>
<td align="right">4022</td>
<td align="right">0.6</td>
<td align="right">72.90</td>
<td align="right">4.5</td>
<td align="right">67.3</td>
<td align="right">137</td>
<td align="right">82096</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Vermont</td>
<td align="right">472</td>
<td align="right">3907</td>
<td align="right">0.6</td>
<td align="right">71.64</td>
<td align="right">5.5</td>
<td align="right">57.1</td>
<td align="right">168</td>
<td align="right">9267</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Wisconsin</td>
<td align="right">4589</td>
<td align="right">4468</td>
<td align="right">0.7</td>
<td align="right">72.48</td>
<td align="right">3.0</td>
<td align="right">54.5</td>
<td align="right">149</td>
<td align="right">54464</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Wyoming</td>
<td align="right">376</td>
<td align="right">4566</td>
<td align="right">0.6</td>
<td align="right">70.29</td>
<td align="right">6.9</td>
<td align="right">62.9</td>
<td align="right">173</td>
<td align="right">97203</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Arizona</td>
<td align="right">2212</td>
<td align="right">4530</td>
<td align="right">1.8</td>
<td align="right">70.55</td>
<td align="right">7.8</td>
<td align="right">58.1</td>
<td align="right">15</td>
<td align="right">113417</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">California</td>
<td align="right">21198</td>
<td align="right">5114</td>
<td align="right">1.1</td>
<td align="right">71.71</td>
<td align="right">10.3</td>
<td align="right">62.6</td>
<td align="right">20</td>
<td align="right">156361</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Florida</td>
<td align="right">8277</td>
<td align="right">4815</td>
<td align="right">1.3</td>
<td align="right">70.66</td>
<td align="right">10.7</td>
<td align="right">52.6</td>
<td align="right">11</td>
<td align="right">54090</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Hawaii</td>
<td align="right">868</td>
<td align="right">4963</td>
<td align="right">1.9</td>
<td align="right">73.60</td>
<td align="right">6.2</td>
<td align="right">61.9</td>
<td align="right">0</td>
<td align="right">6425</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Illinois</td>
<td align="right">11197</td>
<td align="right">5107</td>
<td align="right">0.9</td>
<td align="right">70.14</td>
<td align="right">10.3</td>
<td align="right">52.6</td>
<td align="right">127</td>
<td align="right">55748</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Maryland</td>
<td align="right">4122</td>
<td align="right">5299</td>
<td align="right">0.9</td>
<td align="right">70.22</td>
<td align="right">8.5</td>
<td align="right">52.3</td>
<td align="right">101</td>
<td align="right">9891</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Massachusetts</td>
<td align="right">5814</td>
<td align="right">4755</td>
<td align="right">1.1</td>
<td align="right">71.83</td>
<td align="right">3.3</td>
<td align="right">58.5</td>
<td align="right">103</td>
<td align="right">7826</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Michigan</td>
<td align="right">9111</td>
<td align="right">4751</td>
<td align="right">0.9</td>
<td align="right">70.63</td>
<td align="right">11.1</td>
<td align="right">52.8</td>
<td align="right">125</td>
<td align="right">56817</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">New Jersey</td>
<td align="right">7333</td>
<td align="right">5237</td>
<td align="right">1.1</td>
<td align="right">70.93</td>
<td align="right">5.2</td>
<td align="right">52.5</td>
<td align="right">115</td>
<td align="right">7521</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">New York</td>
<td align="right">18076</td>
<td align="right">4903</td>
<td align="right">1.4</td>
<td align="right">70.55</td>
<td align="right">10.9</td>
<td align="right">52.7</td>
<td align="right">82</td>
<td align="right">47831</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Ohio</td>
<td align="right">10735</td>
<td align="right">4561</td>
<td align="right">0.8</td>
<td align="right">70.82</td>
<td align="right">7.4</td>
<td align="right">53.2</td>
<td align="right">124</td>
<td align="right">40975</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Pennsylvania</td>
<td align="right">11860</td>
<td align="right">4449</td>
<td align="right">1.0</td>
<td align="right">70.43</td>
<td align="right">6.1</td>
<td align="right">50.2</td>
<td align="right">126</td>
<td align="right">44966</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Texas</td>
<td align="right">12237</td>
<td align="right">4188</td>
<td align="right">2.2</td>
<td align="right">70.90</td>
<td align="right">12.2</td>
<td align="right">47.4</td>
<td align="right">35</td>
<td align="right">262134</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Virginia</td>
<td align="right">4981</td>
<td align="right">4701</td>
<td align="right">1.4</td>
<td align="right">70.08</td>
<td align="right">9.5</td>
<td align="right">47.8</td>
<td align="right">85</td>
<td align="right">39780</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Washington</td>
<td align="right">3559</td>
<td align="right">4864</td>
<td align="right">0.6</td>
<td align="right">71.72</td>
<td align="right">4.3</td>
<td align="right">63.5</td>
<td align="right">32</td>
<td align="right">66570</td>
<td align="right">1</td>
</tr>
</tbody>
</table></div>
<p><strong>I hope that this tutorial was helpful to you! Good luck with your next clustering analysis!</strong></p>
</div>
<div id="sources" class="section level2">
<h2>
<span class="header-section-number">27.6</span> Sources<a class="anchor" aria-label="anchor" href="#sources"><i class="fas fa-link"></i></a>
</h2>
<p>Giordani, P., Ferraro, M. B., &amp; Martella, F. (2020). Introduction to Clustering. <a href="https://doi.org/10.1007/978-981-13-0553-5_1" class="uri">https://doi.org/10.1007/978-981-13-0553-5_1</a></p>
<p>Sultana, S. (2020, December 21). How the Hierarchical Clustering Algorithm Works. Retrieved October 24, 2021, from <a href="https://dataaspirant.com/hierarchical-clustering-algorithm/#t-1608531820434" class="uri">https://dataaspirant.com/hierarchical-clustering-algorithm/#t-1608531820434</a></p>
<p>Rawat, S. (2021, June 25). 6 Types of Clustering Algorithms in Machine Learning | Analytics Steps. Retrieved October 23, 2021, from <a href="https://www.analyticssteps.com/blogs/6-types-clustering-algorithms-machine-learning" class="uri">https://www.analyticssteps.com/blogs/6-types-clustering-algorithms-machine-learning</a></p>
<p>Datanovia. (n.d.). Agglomerative Hierarchical Clustering - Datanovia. Retrieved October 24, 2021, from <a href="https://www.datanovia.com/en/lessons/agglomerative-hierarchical-clustering/" class="uri">https://www.datanovia.com/en/lessons/agglomerative-hierarchical-clustering/</a></p>
<p>TechVidvan. (n.d.). Cluster Analysis in R - Complete Guide on Clustering in R - TechVidvan. Retrieved October 24, 2021, from <a href="https://techvidvan.com/tutorials/cluster-analysis-in-r/" class="uri">https://techvidvan.com/tutorials/cluster-analysis-in-r/</a></p>
<p>R Bloggers. (2019, July). Customer Segmentation using RFM Analysis - Rsquared Academy Blog - Explore Discover Learn. Retrieved October 24, 2021, from <a href="https://blog.rsquaredacademy.com/customer-segmentation-using-rfm-analysis/" class="uri">https://blog.rsquaredacademy.com/customer-segmentation-using-rfm-analysis/</a></p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="colors.html"><span class="header-section-number">26</span> Colors</a></div>
<div class="next"><a href="how-to-integrate-r-with-postgresql.html"><span class="header-section-number">28</span> How to Integrate R with PostgreSQL</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#tutorial-on-cluster-analysis"><span class="header-section-number">27</span> Tutorial on Cluster Analysis</a></li>
<li><a class="nav-link" href="#what-is-clustering-analysis"><span class="header-section-number">27.1</span> What is Clustering Analysis?</a></li>
<li>
<a class="nav-link" href="#what-types-of-clustering-analysis-exist"><span class="header-section-number">27.2</span> What Types of Clustering Analysis Exist?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#centroid-based-algorithms"><span class="header-section-number">27.2.1</span> Centroid-based Algorithms</a></li>
<li><a class="nav-link" href="#hierarchical-algorithms"><span class="header-section-number">27.2.2</span> Hierarchical Algorithms</a></li>
<li><a class="nav-link" href="#distribution-based-algorithms"><span class="header-section-number">27.2.3</span> Distribution-based Algorithms</a></li>
<li><a class="nav-link" href="#density-based-algorithms"><span class="header-section-number">27.2.4</span> Density-based Algorithms</a></li>
</ul>
</li>
<li><a class="nav-link" href="#how-does-cluster-analysis-work-on-paper"><span class="header-section-number">27.3</span> How Does Cluster Analysis Work on Paper?</a></li>
<li>
<a class="nav-link" href="#how-does-cluster-analysis-work-in-r"><span class="header-section-number">27.4</span> How Does Cluster Analysis Work in R?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-preparation"><span class="header-section-number">27.4.1</span> Data Preparation</a></li>
<li><a class="nav-link" href="#centroid-based-algorithms-1"><span class="header-section-number">27.4.2</span> Centroid-based Algorithms</a></li>
<li><a class="nav-link" href="#hierarchial-algorithms"><span class="header-section-number">27.4.3</span> Hierarchial Algorithms</a></li>
<li><a class="nav-link" href="#distribution-based-algorithms-1"><span class="header-section-number">27.4.4</span> Distribution-based Algorithms</a></li>
<li><a class="nav-link" href="#density-based-algorithms-1"><span class="header-section-number">27.4.5</span> Density-based Algorithms</a></li>
</ul>
</li>
<li><a class="nav-link" href="#using-clustering-for-further-analysis"><span class="header-section-number">27.5</span> Using Clustering for Further Analysis</a></li>
<li><a class="nav-link" href="#sources"><span class="header-section-number">27.6</span> Sources</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jtr13/cc21fall2/blob/main/clustering_analysis_tutorial.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jtr13/cc21fall2/edit/main/clustering_analysis_tutorial.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>EDAV Fall 2021 Tues/Thurs Community Contributions</strong>" was written by . It was last built on 2021-11-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
